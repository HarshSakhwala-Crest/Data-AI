{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Models with LangChain\n",
    "\n",
    "LangChain supports multiple types of models for **LLM-based applications**:\n",
    "- **Large Language Models (LLMs)**\n",
    "- **Chat Models**\n",
    "- **Text Embedding Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Large Language Models (LLMs)**\n",
    "- LLMs take **text input** and generate **text output**.\n",
    "- LangChain provides an **LLM class** as an abstraction layer for different model providers.\n",
    "- Example of invoking an **Amazon Titan LLM** via **LangChain**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=\"us-east-1\")\n",
    "inference_modifiers = {\"temperature\": 0.3, \"maxTokenCount\": 512}\n",
    "\n",
    "llm = BedrockLLM(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"amazon.titan-tg1-large\",\n",
    "    model_kwargs=inference_modifiers,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"What is the largest city in Vermont?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Custom models**\n",
    "- Amazon Bedrock allows users to fine-tune foundation models (FMs) for better performance in specific use cases.\n",
    "- Example of invoking a custom model provisioned in Amazon Bedrock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "custom_llm = BedrockLLM(\n",
    "    credentials_profile_name=\"bedrock-admin\",\n",
    "    provider=\"cohere\",\n",
    "    model_id=\"<Custom model ARN>\",  # ARN like 'arn:aws:bedrock:..'\n",
    "    model_kwargs={\"temperature\": 1},\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "response = custom_llm.invoke(\"What is the recipe for mayonnaise?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chat models**\n",
    "- Chatbots and AI Assistants improve customer experience while reducing operational costs.\n",
    "- LangChain provides a chat models component for processing conversational input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock as Bedrock\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = Bedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": 0.1})\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"I would like to try Indian food, what do you suggest should I try?\")\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text embedding models**\n",
    "- Text embeddings convert text into numerical vectors that capture semantic meaning.\n",
    "- Embeddings are useful for:\n",
    "  - Semantic Search\n",
    "  - Text Classification\n",
    "  - Information Retrieval\n",
    "  - Query Analysis\n",
    "- Amazon Titan Embeddings Model generates high-quality embeddings for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    region_name=\"us-east-1\",\n",
    "    model_id=\"amazon.titan-embed-text-v1\"\n",
    ")\n",
    "\n",
    "vector = embeddings.embed_query(\"Cooper is a puppy that likes to eat beef\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The embedding vector represents the meaning rather than the exact string.\n",
    "- Synonyms will have similar embeddings, even if the words differ.\n",
    "- with 0 being most similar and 1 being least similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline:** \"Cooper is a dog that likes to eat beef.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score |\tText <br>\n",
    "0.035 |\t**Cooper is a puppy that likes to eat beef.** <br>\n",
    "0.083 |\t**Beef is what a dog named Cooper likes.** <br>\n",
    "0.109 |\tCooper is a dog that likes to eat steak. <br>\n",
    "0.135 |\tCooper is a dog that hates eating beef. <br>\n",
    "0.184 |\tCooper is a dog that likes to eat chicken. <br>\n",
    "0.192 |\tFido is a dog that likes to eat beef. <br>\n",
    "0.194 |\tCooper is a cat that likes to eat beef. <br>\n",
    "0.264 |\tSpot is a dog that likes to eat beef. <br>\n",
    "0.351 |\tCooper is a man that likes to eat beef. <br>\n",
    "0.799 |\t**Cooper ist ein Hund, der gerne Rindfleisch frisst. (German translation)** <br>\n",
    "1.016 |\tA cooper is someone that makes barrels. <br>\n",
    "1.293 |\tAmazon Web Services provides cloud computing solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replacing words (e.g., \"dog\" â†’ \"puppy\") has minimal effect on similarity.\n",
    "- Changing sentence structure (e.g., \"Beef is what a dog named Cooper likes.\") still retains meaning.\n",
    "- Translations (e.g., German version) are more similar than unrelated phrases.\n",
    "- Embeddings help associate meaning across different languages and across different meanings of words."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
